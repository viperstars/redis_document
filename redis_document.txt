redis的安装
1，下载
wget http://download.redis.io/releases/redis-2.8.19.tar.gz
2，解压
tar xzf redis-2.8.19.tar.gz
cd redis-2.8.19
3，不需要./configure
make
4，启动服务
./src/redis-server
5，使用客户端工具连接
./src/redis-cli
redis> set foo bar
OK
redis> get foo
"bar"

启动方式
1，通过./redis-server启动并附加部分选项
./redis-server --port 6380 --slaveof 127.0.0.1 6379
2，或直接指定配置文件
./redis-server /home/redis/redis.conf

以下是./redis-server的使用帮助
Usage: ./redis-server [/path/to/redis.conf] [options]
       ./redis-server - (read config from stdin)
       ./redis-server -v or --version
       ./redis-server -h or --help
       ./redis-server --test-memory <megabytes>

Examples:
       ./redis-server (run the server with default conf)
       ./redis-server /etc/redis/6379.conf
       ./redis-server --port 7777
       ./redis-server --port 7777 --slaveof 127.0.0.1 8888
       ./redis-server /etc/myredis.conf --loglevel verbose

Sentinel mode:
       ./redis-server /etc/sentinel.conf --sentinel

3，也可以通过提供的sysV脚本来启动
cp utils/redis_init_script /etc/init.d/redis
chmod 755 /etc/init.d/redis
/etc/init.d/redis可以接受两个参数，分别是start和stop

如何停止
1，可以利用sysV脚本停止
2，进入命令行界面，并shutdown
src/redis-cli
redis> shutdown
3，向进程发送SIGTERM信号
kill pid

redis的key
redis的key是二进制安全的，意味着可以用任何的二进制序列做key
注意事项：
太长或者太短的key都不是太好，太长会导致查找速度变慢，太短会导致可读性差
类似"object-type:id"这样的key相对较好
key允许的最大值为512MB

redis的value
字符串
可以关联到redis的key的最简单的value，字符串既是字符串，类似'1', '5', '19'这样的可以当数字来使用
基本用法
1，关联key和value
set key value [nx|xx]
2，获取key的值
get key
3，关联多组key和value
mset key1 value1 key2 value2 key3 value3 ......
4，获取多个key的值
mget key1 key2 key3 ......
5，检查key是否存在
exists key
6，删除key
del key
7，查看key对应值的类型
type key
8，为key设置时间
expire key time(seconds)
9，设置值时
set key ex time(seconds)
10，查看key的生存时间
ttl key
11，对于数字可以对其进行加减
给key对应的值加1
incr key
给key对应的值减1
desc key
给key的值增加相应值n
incrby key n
给key的值减去相应值n
descby key n

列表
一列有顺序的元素，可以在头部或者尾部进行插入
1，为列表增加元素
从左边（头部）插入
lpush key value1 [value2 value3 ....]
从右边（尾部）插入
rpush key value1 [value2 value3 ....]
2，查看列表中的元素
lrange index1 index2
3，删除列表中的元素
从左边（头部）删除
lpop key
从右边（尾部）删除
rpop key
仅将列表中index1至index2的元素保留，删除其他的元素
ltrim key index1 index2
4，获取多列中元素的个数
llen key
4，删除一个key
del key

列表非常适合用来实现队列
如果需要让某个进程向列表中push一个元素，用另外一个进程来处理列表中的元素，这就是生产者消费者模型
生产者通过lpush向队列里push元素
消费者使用rpop来获取队列中的元素并处理

rpop在队列为空时工作的不好，如果队列为空会返回null，使用brpop会更好
brpop会在对列为空时处于阻塞状态，直到有队列中有新元素或者指定的时间超时

列表的适用场景
1，在社交网络中记录最近发布的更新
    每当用户发布了新的照片，可以将其id通过lpush进一个列表
	当用户访问主页的时候，通过lrange 0 9来获取最近发布的十篇文章
	需要保留最近N篇文章时，通过ltrim 0 N来删除除了0到N之间的其他文章
2，进程间通信，利用生产者-消费者模型

hash
hash就是key对应的value也是多组key/value的对应关系
1，设置key和value
设置单个值
hset key key1 value1
设置多个值
hmset key key1 value1 key2 value2 key3 value3
2，通过key获取值
获取单个值
hset key key1
获取多个值
hmget key key1 key2 key3
3，为值增加相应的值
hincr key key1
hincrby key key1 n

集合
集合是无序的字符串的集合
1，添加元素
sadd key value
2，列出集合中的元素
smembers key
3，检查是否是集合中的元素
sismember key value
4，随机删除集合中的元素
spop key
5，集合的交集
sinter key1 key2 key3
6，计算集合中元素的个数
scard key

有序集合
有序集合像是集合和hash的混合体，有序集合中包括有序的，唯一的字符串元素
1，为有序集合添加元素
zadd key score value
2，根据score列出元素
zrange key score1 score2 [withscores]
3，在列出元素时反向排列
zrevrange key score1 score2
有序集合的排序方式
如果A和B是两个拥有不同值的元素，那么如果A.score大于B.score，则A>B
如果A.score等于B.score，那么A和B的大小取决于A，B字符串在字典中的大小
A和B不能相等，因为redis的有序集合中不能有相同元素
4，通过score的大小来排序
zrangebyscore key score1 score2（指明范围）
5，通过range来删除元素
zremrangebyscore key score1 score2（指明范围）
6，如果score都相同，而key不相同时，需要用zrangebylex排序
zrangebylex key [起始字母 [结束字母

有序集合的应用：排行榜
有序集合的score可以在任意时间update，使用zadd就可以更新其score，因此有序集合可以用来实现排行榜
最典型的应用就是facebook游戏，将用户通过其得分来进行排名

bitmap
bitmap并不是一个数据类型，而是一个基于字符串的面向bit的操作
bit操作可以分为以下两类，第一类是单个操作，例如设置一个0为1，或者是获得其值
第二类是针对多个bit的操作，例如获得一个既定范围的bits的数量
bitmap最大的优点是在存储信息时节省空间
1，设置bit值
setbit key index value（0/1）
2，获得bit值
getbit key index
3，计数
bitcount key

bit还有bitop和bitpos操作
bitop用来实现bit级别的操作，包括与，或，非
bitpos用来查找指定值（0/1）的bit

bitmap适合的应用：
1，实时分析系统
2，高存储效率高性能关联至对象id的布尔值信息

hyperloglogs
hyperloglogs用于统计不同对象的值，使用内存较少，例如记录网站访问的IP地址，使用集合保存一年独立IP数量需要540G，使用hyperloglog只需要4.32MB
hyperloglogs只能添加元素以及返回元素的基数，不能返回所有元素
当看到新元素的时候，通过pfadd加入hll
当需要检查元素的数量时，使用pfcount
使用场景：用来统计每天用户发来的不同的请求

redis管理：
安装时的注意事项：
1，建议使用linux操作系统
2，修改/etc/sysctl.conf中vm.overcommit_memory = 1，表示内核允许分配所有的物理内存，而不管当前的内存状态如何
3，确保关闭了linux的transparent huge pages，通过echo never > /sys/kernel/mm/transparent_hugepage/enabled来实现
4，准备一些swap空间，建议是和内存一样大，否则redis可能会崩溃或是被oom杀死
5，配置一个明确的maxmemory值，否则redis可能会在接近系统最大内存时出错
6，如果在一个写操作频繁的场景使用redis，并使用rdb或者aof时，redis可能会使用平时两倍的内存
7，当使用了daemontools时，将daemonize设置为no
8，如果将持久化特性关闭时，redis仍然需要在有主从复制时使用rdb文件
9，在使用复制时，确保master开启了持久化存储，或者关闭在奔溃后自动重启的功能，如果master开启时载入空的文件，那么slave会抹掉所有数据

redis升级
1，将新版本的redis作为老版本的slave，可以在同一个服务器上或者时不同的服务器上
2，等待主从同步完成
3，使用info来确认主从上的key的数量是相同的
4，关闭slave的只读， CONFIG SET slave-read-only no
5，配置所有的client来使用新的服务器
6，在确定了master不在接受任何请求时，在slave上执行SLAVEOF NO ONE，并关闭master

redis持久化
两种持久化方案
1，rdb，任意时间点的快照，类似于使用mysqldump的备份
2，aof，记录服务器上的每个写操作，在服务器启动时加载，用于重建数据，类似于binlog
可以不启用持久化
也可以同时使用rdb和aof

rdb的优势：
rdb一个任意时间点的数据文件，适用于备份，也适用于灾难恢复
相对于aof来说，重启时恢复数据更快

劣势：
如果希望能够将数据的丢失率降到最低，那么rdb不适合，因为rdb是在固定的频率对数据做快照
rdb需要为了持续写入磁盘而fork()子进程，如果数据太多，那么fork()会花费相当长的时间，可能导致redis停止服务client

aof的优势：
aof的持久性更好，有多种fsync策略可以选择，默认的每秒fsync的性能依然很好
aof是追加式存储，不会因为断电而导致不可用，如果因为某些原因仅仅写入一半数据，也有工具可以很快修复
当aof过大时，redis会自动的重构aof文件
aof中包括了所有的操作，格式也很好理解，可以很轻松的导出

劣势：
对于同样的数据，aof文件通常大于rdb文件
在某些fsync策略下，aof可能比rdb要慢，在数据很多的情况下，rdb的速度较快
在先前的使用中，执行某些特定的命令可能会引起一些bug

如果需要很好的保证数据的可靠性，那么应该两种方案同时使用

不鼓励仅仅使用aof来实现持久化存储，因为rdb也能提供很好的数据持久化功能，而aof有一些bug历史

默认情况下redis开启了rdb
save seconds keys(change)

save 60 1000
如果有至少1000key改动的话就每60s写入磁盘

如何工作：
1，redis fork()一个子进程
2，子进程将数据写入一个临时rdb文件
3，写入完成后，用新的rdb文件替换旧的

开启aof
appendonly yes

redis还支持aof重构
配置了bgrewrite后，redis会在后台自动重构aof，构成一个最短的命令序列

可以配置fsync数据到硬盘的频率
当有新的命令执行时就fsync数据到aof文件，很慢，很安全
每秒fsync数据到aof文件，足够快，当灾难发生时会丢失1s的数据
从不fsync，仅仅将数据交给操作系统，很快，很不安全

建议的频率是每秒fsync一次

如果aof文件损坏该如何处理？
1，备份aof文件
2，使用工具redis-check-aof --fix
3，diff查看新旧aof文件
4，在启动时使用新的aof文件

如何工作：
1，redis fork()一个子进程
2，子进程开始写入一个临时aof文件
3，主进程将所有的改变都存放在系统缓冲区
4，当子进程完成写入之后，主进程得到信号，将缓存的数据写入子进程产生的aof文件
5，redis将重命名新的文件，并开始写入新数据至新文件

redis安全相关
redis是设计在被信任的网络环境中使用信任的客户端来访问的

修改监听地址
bind IP

例如：
bind 127.0.0.1

redis提供一个很小的layer来实现验证
redis会拒绝没有通过认证的客户端的请求
client会通过发送auth命令和password来完成验证

服务端使用以下来实现验证
requirepass "password"

客户端使用以下来完成验证
auth "password"

redis在处理请求时速度很快，同时可以相应多个客户端的请求
因为redis高性能的特点，在很短时间内尝试猜测非常多个密码是有可能的，因此请确保使用的密码足够复杂和足够长，以免遭受密码猜测攻击
redis的密码会记录在redis.conf和客户端的配置文件中

redis不支持数据加密

命令重命名
如果需要禁用一些命令，可以通过将命令重命名，这样客户端只能发送受限制的命令
rename-command command1 command2

例如：
rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52

redis加密
很多情况下都是用SSL来实现加密，但是也可以使用Spiped
Spiped可以创建一个对称加密的管道，这样可以通过这个加密的管道来通信

redis信号处理（仅仅适用于redis2.6或者以上版本）
1，SIGTERM
SIGTERM信号告诉redis需要平滑关闭，类似于通过命令行工具执行shutdown操作
当接受了SIGTERM信号之后，redis会完成以下操作
如果后台有子进程在保存rdb或者aof文件，那么子进程会被杀死
如果配置了aof，那么redis会调用fsync来将缓存中的数据写入aof文件
如果配置了rdb，那么会同步保存文件
如果redis是后台运行，那么pid文件会被删除
如果启用了socket，那么socket文件会被删除
服务器会关闭并返回0

2，SIGSEGV，SIGBUS，SIGFPE，SIGILL
当接受到以上信号时，redis会崩溃
并有以下操作：
log文件中会记录bug报告
redis2.8会进行一个快速的内存检测
如果redis是后台运行，那么pid文件会被删除
redis会自己发送一个收到的信号，以保证收到的信号时执行默认的操作

当子进程被kill时会发生什么
当aof子进程被kill后，redis会丢弃临时的aof文件，并在一段时间后继续进行aof写入操作
当rdb子进程被kill后，redis会将此视为一个更严重的错误来处理：
redis会继续处理读命令
redis会对任何写命令返回一个MISCONFIG错误
当再次创建新的rdb文件成功后，就不会继续一样操作

phpredis的安装
wget https://codeload.github.com/phpredis/phpredis/zip/develop
wget http://pecl.php.net/get/igbinary

先安装igbinary
tar xf igbinary-1.2.1.tgz
cd igbinary-1.2.1
/data/webserver/php/bin/phpize
./configure --with-php-config=/data/webserver/php/bin/php-config
make && make install

再安装phpredis
unzip phpredis-develop.zip
cd phpredis-develop
/data/webserver/php/bin/phpize
./configure --enable-redis-igbinary --with-php-config=/data/webserver/php/bin/php-config
make && make install

给php.ini增加extensions="redis.so"

新建测试页面
<?php
$redis = new Redis();
$redis->connect('127.0.0.1',6379);
$redis->set('haha','www.viperstars.com');
echo 'haha:'.$redis->get('haha');
echo 'br>';
echo 'hehe:'.$redis->get('hehe');
?>

redis版本相关
redis使用和Linux类似的版本命名方式：主版本号.次版本号.修正版本号，次版本号为偶数时表示此版本是一个稳定版
而为奇数时则是非稳定版
目前redis有以下几个版本
稳定版2.8：稳定版本，提供了很多新功能
测试版3.0：引入redis集群，并提升了速度，稳定版大概在3月推出
非稳定版：正在开发的版本，仅供测试新特性和性能表现

建议使用2.8.19版本，此版本为目前最新稳定版

release note
https://raw.githubusercontent.com/antirez/redis/2.8/00-RELEASENOTES

一些issues都在github上
https://github.com/antirez/redis/issues?page=1&q=is%3Aissue+is%3Aopen

redis自带的测试模式
redis的很多问题都是由于内存的问题导致的，所以在运行redis之前可以对将要分配的内存大小做一个测试
./redis-server --test-memory memory-size

可以在server上使用
./redis-cli --intrinsic-latency seconds 来检测系统最小延迟

可以在客户端上使用
./redis-cli --latency -h `host` -p `port` 来检测最小延迟

runtest可以对redis的各种功能进行测试
./runtest

 The End

Execution time of different units:
  3 seconds - unit/quit
  3 seconds - unit/printver
  5 seconds - unit/scan
  6 seconds - unit/multi
  6 seconds - unit/auth
  8 seconds - unit/protocol
  12 seconds - unit/expire
  24 seconds - unit/type/list
  17 seconds - integration/aof
  6 seconds - integration/rdb
  1 seconds - unit/pubsub
  4 seconds - integration/convert-zipmap-hash-on-load
  3 seconds - unit/slowlog
  35 seconds - unit/type/list-2
  1 seconds - unit/introspection
  2 seconds - unit/limits
  40 seconds - unit/type/hash
  11 seconds - unit/scripting
  44 seconds - unit/other
  13 seconds - unit/dump
  56 seconds - unit/aofrw
  60 seconds - unit/type/set
  57 seconds - integration/replication-psync
  70 seconds - unit/type/zset
  36 seconds - unit/maxmemory
  29 seconds - unit/bitops
  69 seconds - integration/replication-2
  78 seconds - unit/sort
  77 seconds - integration/replication
  81 seconds - unit/type/list-3
  83 seconds - unit/basic
  61 seconds - unit/obuf-limits
  93 seconds - integration/replication-4
  93 seconds - integration/replication-3
  47 seconds - unit/hyperloglog
  334 seconds - unit/memefficiency

\o/ All tests passed without errors!

Cleanup: may take some time... OK

如果出现问题可以反馈给redis的google group
http://groups.google.com/group/redis-db

排错步骤：
1，确定服务器不是被一些执行速度很慢的命令阻塞
2，对于EC2的用户，使用基于HVM的EC2实例，否则fork()的速度很慢
3，transparent huge pages必须关闭
4，如果运行在虚拟机上，那么固有的延迟是不会影响redis
5，开启并使用延迟监控的特性，这样可以得到一个可读的延迟事件描述

redis通信协议
Redis 协议在以下三个目标之间进行折中：
易于实现
可以高效地被计算机分析
可以很容易地被人类读懂

网络层
客户端和服务器通过TCP协议来进行数据交互， 服务器默认的端口号为 6379
客户端和服务器发送的命令或数据一律以 "\r\n"（CRLF）结尾

请求响应模型
redis接受带有不同参数的命令，一旦接收到命令，redis会处理并回复客户端
这是最简单的请求响应模型，但是有以下两个例外:
1，redis支持流水线操作，所以客户端可以一次发送多个命令，然后等待响应
2，当redis客户端使用订阅了一个pub/sub频道时，通信协议变成了“推送”模型，客户端不再需要发送命令，服务端在收到信息时立刻推送至客户端

请求
请求的一般形式：
*<参数数量> CRLF
$<参数 1 的字节数量> CRLF
<参数 1 的数据> CRLF
...
$<参数 N 的字节数量> CRLF
<参数 N 的数据> CRLF
命令本身也作为协议的其中一个来发送

回复
Redis 命令会返回多种不同类型的回复
通过检查服务器发回数据的第一个字节， 可以确定这个回复是什么类型：
状态回复（status reply）是以 "+" 开头，"\r\n" 结尾的单行字符串
错误回复（error reply）是以 "-" 开头，"\r\n" 结尾的单行字符串，错误回复只在某些地方出现问题时发送
整数回复（integer reply）是以 ":" 开头，"\r\n" 结尾的字符串表示的整数
批量回复（bulk reply）是以 "$" 开头，接下来跟着的是表示实际回复长度的数字值，之后跟着一个 "\r\n"，再后面跟着的是实际回复数据，以"\r\n" 结尾
多条批量回复（multi bulk reply）是以 "*" 开头， 后跟一个字符串表示的整数值， 这个值记录了多条批量回复所包含的回复数量，再跟一个 "\r\n" 

redis-cli的一些使用方法
./redis-cli --stat 可以查看redis目前使用的内存，负载，以及子进程的情况
./redis-cli -r n command 可以重复执行command n次
./redis-cli --slave 模拟一个slave，用来查看从master同步的命令
./redis-cli --intrinsic-latency seconds 来检测系统最小延迟
./redis-cli --latency -h `host` -p `port` 来检测最小延迟

广泛的使用
Twitter使用Redis来储存用户时间线( user timeline )
StackOverflow使用Redis来进行缓存和消息分发
Pinterest使用Redis来构建关注模型( follow model )和兴趣图谱( interest graph )
Flickr使用Redis来构建队列
Github使用Redis作为持久化的键值对数据库，并使用Resquet来实现消息队列
新浪微博使用Redis来实现计数器、反向索引、排行榜、消息队列，并储存用户关系
知乎使用Redis来进行计数、缓存、消息分发和任务调度

redis的使用场景
1，计数器
使用redis的INCR命令
例如需要记录一个社交网络用户主页的访问数
1，用户访问某个用户的主页
2，使用INCR使访问数加一
3，查看INCR命令的返回值
4，显示INCR之后用户的访问数

2，用户“圈子”
使用redis的集合
例如Google+，我们需要为每个用户维护几个“圈子”，可以使用用户名加圈子名当做key，每个圈子中的用户当做元素
这样我们就可以通过key来获得圈子中的用户，不仅如此，集合的交并补操作可以实现很多有趣的功能：将某个用户的所有圈子求并集可以得到用户圈子内的所有用户
将某个用户的某几个圈子求交集可以得到用户圈子之间的共同好友，为两个用户的圈子求交集可以得到两个用户的共同好友
为两个用户的圈子求并集并求某个用户的补集可以为用户推荐别的用户的好友等等

3，使用pub/sub来建立一个实时聊天系统
由于redis原生支持pub/sub，故非常适合用来实现聊天系统
subscribe, unsubscribe和publish三个命令实现了发布与订阅信息泛型， 在这个实现中，发送者（发送信息的客户端）不是将信息直接发送给特定的接收者（接收信息的客户端）， 而是将信息发送给频道， 然后由频道将信息转发给所有对这个频道感兴趣的订阅者
发送者无须知道任何关于订阅者的信息， 而订阅者也无须知道是那个客户端给它发送信息， 它只要关注自己感兴趣的频道即可
对发布者和订阅者进行解构， 可以极大地提高系统的扩展性
redis 的发布与订阅实现支持模式匹配： 客户端可以订阅一个带 * 号的模式， 如果某个/某些频道的名字和这个模式匹配， 那么当有信息发送给这个/这些频道的时候， 客户端也会收到这个/这些频道的信息

用一个客户端订阅管道
redis 127.0.0.1:6379> SUBSCRIBE channelone
Reading messages... (press Ctrl-C to quit)
1) "subscribe"
2) "channelone"
3) (integer) 1

另一个客户端往这个管道推送信息
redis 127.0.0.1:6379> PUBLISH channelone hello
(integer) 1
redis 127.0.0.1:6379> PUBLISH channelone world
(integer) 1

然后第一个客户端就能获取到推送的信息
redis 127.0.0.1:6379> SUBSCRIBE channelone
Reading messages... (press Ctrl-C to quit)
1) "subscribe"
2) "channelone"
3) (integer) 1
1) "message"
2) "channelone"
3) "hello"
1) "message"
2) "channelone"
3) "world"

2、按一定模式批量订阅
用下面的命令订阅所有channel开头的信息通道
redis 127.0.0.1:6379> PSUBSCRIBE channel*
Reading messages... (press Ctrl-C to quit)
1) "psubscribe"
2) "channel*"
3) (integer) 1

在另一个客户端对两个推送信息
redis 127.0.0.1:6379> PUBLISH channelone hello
(integer) 1
redis 127.0.0.1:6379> PUBLISH channeltwo world
(integer) 1
然后在第一个客户端就能收到推送的信息
redis 127.0.0.1:6379> PSUBSCRIBE channel*
Reading messages... (press Ctrl-C to quit)
1) "psubscribe"
2) "channel*"
3) (integer) 1
1) "pmessage"
2) "channel*"
3) "channelone"
4) "hello"
1) "pmessage"
2) "channel*"
3) "channeltwo"
4) "world"

编程示例：
https://gist.github.com/348262

4，实现基于倒排索引的全文搜索
倒排索引是一个索引数据结构，映射了单词和单词在文件，文档和数据库中等的位置，一般用于全文索引，但是需要在搜索前先建立索引
实现方式是每个词对应一个集合，集合中包括包含这个词的文档ID，为了实现快速搜索，我们可以先进行索引，搜索请求会被切分为单词，并内部搜索匹配的集合，然后再返回对应的文档ID
不仅如此，还可以可以在搜索时利用有序集合，将词与文档的相关性做index然后进行排序，这样就可以得到根据相关性的排行
当有并发搜索请求时，可以使用redis的multi/exec特性

5，分析学和基于时间的数据
对于传统的RDBMS来说，存储此类数据来说是一个挑战，例如你需要对进向流量进行限速，那么就需要快速高并发的数据更新，或者是记录网站的访问数量，这需要复杂的数据矩阵
redis非常适合存储此类数据，快速的原子性操作hincr和hincrby结合快速的数据搜索使得redis非常适合
redis中最适合的数据结构是hash，可以用hget和hmget来取得需要的数据，hincr和hincrby来增加数值，用sort来排序

6，队列系统
如果需要让某个进程向列表中push一个元素，用另外一个进程来处理列表中的元素，这就是生产者消费者模型
生产者通过lpush向队列里push元素
消费者使用rpop来获取队列中的元素并处理
rpop在队列为空时工作的不好，如果队列为空会返回null，使用brpop会更好
brpop会在对列为空时处于阻塞状态，直到有队列中有新元素或者指定的时间超时

7, 记录最近发布的更新
每当用户发布了新的照片或者文章，可以将其id通过lpush进一个列表
当用户访问主页的时候，通过lrange 0 9来获取最近发布的十篇文章
需要保留最近N篇文章时，通过ltrim 0 N来删除除了0到N之间的其他文章

8，排行榜
有序集合的index可以在任意时间update，使用zadd就可以更新其index，因此有序集合可以用来实现排行榜
最典型的应用就是facebook游戏，将用户通过其得分来进行排名

9，活跃用户以及用户行为统计
使用bitmap可以实现活跃用户以及用户行为统计
redis允许使用二进制数据的Key(binary keys) 和二进制数据的Value(binary values)，Bitmap就是二进制数据的value
为了统计今天登录的用户数，我们建立了一个bitmap，每一位标识一个用户ID
当某个用户访问我们的网页或执行了某个操作，就在bitmap中把标识此用户的位置为1
在Redis中获取此bitmap的key值是通过用户执行操作的类型和时间戳获得的

为了统计今天听过歌曲的用户，我们建立了一个bitmap，每一位标识一个用户ID，当某个用户在今天听了歌曲，就在bitmap中把标识此用户的位置为1
如果要按周或月统计，只要对这周或这个月的所有bitmap求并集，得出新的bitmap，再对它做bitcount即可

10，统计用户行为
用来统计每天用户发来的不同的请求，可以使用hyperloglogs
hyperloglogs可以像集合一样去除相同的元素，且占用内存更小，当用户发来请求时，可以将请求的url添加到hyperloglogs中
hyperloglogs会去除相同的请求

redis在新浪微博业务中的使用方式

hash sets：关注列表，粉丝列表，双向关注列表(key-value(field)， 排序)
string(counter)：微博数， 粉丝数， ... (避免了select count(*) from ... )
sort sets(自动排序)：TopN，热门微博等，自动排序
lists(queue)：push/sub提醒...

上述四种, 从精细化控制方面，hash sets和string(counter)推荐使用, sort sets和lists(queue)不推荐使用
还可通过二次开发，进行精简，比如: 存储字符改为存储整形, 16亿数据, 只需要16G内存
存储类型保存在3种以内，建议不要超过3种

redis在新浪微博中的应用
http://blog.me115.com/2013/12/452

Pinterest的follow模型及兴趣图谱
Facebook的follow关系是相互的，在两个用户之间，而Twitter的通常是一对多。对于Pinterest来说，follow可以是单向的，但超出了个人与个人的follow关系，并延伸到board。随着人们follow更多的人和board，他们主页的内容会更加贴近他们的兴趣，兴趣图谱就会进一步构建。
例如，如果A开始follow了B，她会follow他所有的board，如果B创建了一个新的board，她会自动follow该board。如果A开始follow了B的board，他会看到他所有的pins。A也将被列为该board的follower。我们称之为B的board的follower也是隐含的B的follower（而此前A开始follow了B，A则是一个明确的follower）

所以pinterest的用户间的关系如下：
用户明确follow的用户列表，即follow了用户，以及他现在和将来的board
用户隐含follow的用户列表，即follow了某个用户的某个或多个board
用户的所有明确followers列表
用户的所有隐含followers列表
用户明确follow的所有board列表
用户明确没有follow的所有board的列表
board的明确followers
board的明确unfollowers

对应的redis使用的数据结构如下：
使用redis的有序集合来存储用户明确follow的用户列表，并以时间戳为score
使用redis的有序集合来存储用户隐含follow的用户列表，并以时间戳为score
使用redis的有序集合来存储用户的所有明确followers列表，并以时间戳为score
使用redis的有序集合来存储用户的所有隐含followers列表，并以时间戳为score
使用redis的集合来存储用户明确follow的所有board列表
使用redis的集合来存储用户明确没有follow的所有board的列表
使用redis的hash来存储board的明确followers
使用redis的集合来存储board的明确unfollowers

redis在其创始人的网站LLOOGG的工作方式
LLOOGG是一个一个访客信息追踪网站，网站可以通过JavaScript 脚本，将访客的IP地址、所属国家、 阅览器信息、被访问页面的地址等数据传送给LLOOGG.com
然后LLOOGG.com会将这些浏览数据通过web页面实时地展示给用户，并储存起最新的5至10,000条浏览记录以便进行查阅
LLOOGG.com使用列表来储存浏览记录，当列表的长度达到了用户指定的最大长度之后，程序每向列表推入一个新的记录，就需要从列表中弹出一个最旧的记录
从数据结构的角度来看，LLOOGG.com为每个被监视网站构建的都是一个定长先进先出队列（FixedSize First In First Out Queue），这种结构具有以下特点：
固定长度（定长）：队列的长度（也即是 队列包含的项数量）不能超过一个给定的最大值
先进先出：当队列的长度到达最大值时，每向队列推入一个新值，程序就需要从队列中弹出一个最早被推入到列表里面的值

Tumblr基于Redis的消息系统
在Tumblr初期，其通知系统是由MySQL＋Memcached的传统架构组成，但是由于通知系统庞大的添加操作，导致MySQL负担非常大，经常超出InnoDB global transaction max（1024）
于是他们打算重新构建消息系统，首先他们分析了消息系统的应用特点：
按时间排序
唯一性，每一条消息都是唯一的
读写比大概是 60%/30%
每个用户的消息条数一定
数据按用户划分，每个用户只能读自己的消息
基于上面应用特点的考虑，Tumblr选择了Redis的sorted sets作为其数据存储
他们的存储方式是：
给每个用户分配一个sorted sets，其中每一项保存一条通知
每条通知以时间戳为score在sorted sets中进行排序
超出100条通知后进行trim操作
Tumblr的数据量：2300万个BLOG，每个BLOG 100条消息，每条消息体大概160bytes
响应速度：大概每秒提供7,500次请求，每次请求的响应时间小于5ms

事务
MULTI 、EXEC 、DISCARD和WATCH是redis事务的基础
事务可以一次执行多个命令， 并且带有以下两个重要的保证：
事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行，事务在执行的过程中，不会被其他客户端发送来的命令请求所打断
事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行

MULTI命令用于开启一个事务，它总是返回OK
MULTI执行之后， 客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中
当客户端处于事务状态时，所有传入的命令都会返回一个内容为QUEUED的状态回复（status reply），这些被入队的命令将在EXEC命令被调用时执行
另一方面，通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务

EXEC命令负责触发并执行事务中的所有命令：
如果客户端在使用MULTI开启了一个事务之后，却因为断线而没有成功执行EXEC，那么事务中的所有命令都不会被执行
另一方面，如果客户端成功在开启事务之后执行EXEC，那么事务中的所有命令都会被执行

使用事务时可能会遇上以下两种错误：
事务在执行EXEC之前，入队的命令可能会出错。比如说，命令可能会产生语法错误（参数数量错误，参数名错误，等等），或者其他更严重的错误，比如内存不足（如果服务器使用maxmemory 设置了最大内存限制的话）
命令可能在EXEC调用之后失败，举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面等
最重要的是记住这样一条， 即使事务中有某条/某些命令执行失败了，事务队列中的其他命令仍然会继续执行——redis不会停止执行事务中的命令

如果你有使用关系式数据库的经验， 那么“redis在事务失败时不进行回滚，而是继续执行余下的命令”这种做法可能会让你觉得有点奇怪
以下是这种做法的优点：
命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中
因为不需要对回滚进行支持，所以redis的内部可以保持简单且快速

有种观点认为redis处理事务的做法会产生bug，然而需要注意的是，在通常情况下，回滚并不能解决编程错误带来的问题。举个例子，如果你本来想通过INCR命令将键的值加上1， 却不小心加上了2，又或者对错误类型的键执行了INCR，回滚是没有办法处理这些情况的

当执行 DISCARD 命令时，事务会被放弃，事务队列会被清空，并且客户端会从事务状态中退出

WATCH命令可以为redis事务提供check-and-set（CAS）行为
被WATCH的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在EXEC执行之前被修改了，那么整个事务都会被取消，EXEC返回空多条批量回复（null multi-bulk reply）来表示事务已经失败，程序需要做的，就是不断重试这个操作，直到没有发生碰撞为止
这种形式的锁被称作乐观锁， 它是一种非常强大的锁机制。并且因为大多数情况下，不同的客户端会访问不同的键，碰撞的情况一般都很少，所以通常并不需要进行重试

WATCH命令可以被调用多次。对键的监视从WATCH执行之后开始生效，直到调用EXEC为止，用户还可以在单个WATCH命令中监视任意多个键，当EXEC被调用时，不管事务是否成功执行， 对所有键的监视都会被取消，当客户端断开连接时，该客户端对键的监视也会被取消

使用无参数的UNWATCH命令可以手动取消对所有键的监视。对于一些需要改动多个键的事务，有时候程序需要同时对多个键进行加锁，然后检查这些键的当前值是否符合程序的要求 当值达不到要求时，就可以使用 UNWATCH 命令来取消目前对键的监视，中途放弃这个事务，并等待事务的下次尝试

复制

redis 支持简单且易用的主从复制功能， 该功能可以让从服务器成为主服务器的精确复制

以下是关于redis复制功能的几个重要方面：
redis使用异步复制，从redis 2.8开始，从服务器会以每秒一次的频率向主服务器报告复制流的处理进度
一个主服务器可以有多个从服务器
不仅主服务器可以有从服务器， 从服务器也可以有自己的从服务器， 多个从服务器之间可以构成一个图状结构
复制功能不会阻塞主服务器，即使有一个或多个从服务器正在进行初次同步，主服务器也可以继续处理命令请求
复制功能也不会阻塞从服务器，只要在redis.conf文件中进行了相应的设置，即使从服务器正在进行初次同步，服务器也可以使用旧版本的数据集来处理命令查询
不过，在从服务器删除旧版本数据集并载入新版本数据集的那段时间内， 连接请求会被阻塞
你还可以配置从服务器， 让它在与主服务器之间的连接断开时， 向客户端发送一个错误
复制功能可以单纯地用于数据冗余，也可以通过让多个从服务器处理只读命令请求来提升扩展性：比如说，繁重的SORT命令可以交给附属节点去运行
可以通过复制功能来让主服务器免于执行持久化操作，只要关闭主服务器的持久化功能，然后由从服务器去执行持久化操作

无论是初次连接还是重新连接， 当建立一个从服务器时， 从服务器都将向主服务器发送一个SYNC命令
接到SYNC命令的主服务器将开始执行BGSAVE，并在保存操作执行期间，将所有新执行的写入命令都保存到一个缓冲区里面
当BGSAVE执行完毕后，主服务器将执行保存操作所得的.rdb文件发送给从服务器，从服务器接收这个.rdb文件，并将文件中的数据载入到内存中
之后主服务器会以redis命令协议的格式，将写命令缓冲区中积累的所有内容都发送给从服务器

即使有多个从服务器同时向主服务器发送SYNC，主服务器也只需执行一次BGSAVE命令，就可以处理所有这些从服务器的同步请求
从服务器可以在主从服务器之间的连接断开时进行自动重连，在redis 2.8版本之前，断线之后重连的从服务器总要执行一次完整重同步操作，但是从redis 2.8版本开始， 从服务器可以根据主服务器的情况来选择执行完整重同步还是部分重同步

从redis 2.8开始， 在网络连接短暂性失效之后， 主从服务器可以尝试继续执行原有的复制进程，而不一定要执行完整重同步操作
这个特性需要主服务器为被发送的复制流创建一个内存缓冲区，并且主服务器和所有从服务器之间都记录一个复制偏移量和一个主服务器 ID，当出现网络连接断开时，从服务器会重新连接， 并且向主服务器请求继续执行原来的复制进程：
如果从服务器记录的主服务器 ID 和当前要连接的主服务器的 ID 相同，并且从服务器记录的偏移量所指定的数据仍然保存在主服务器的复制流缓冲区里面， 那么主服务器会向从服务器发送断线时缺失的那部分数据， 然后复制工作可以继续执行
否则的话， 从服务器就要执行完整重同步操作
redis 2.8 的这个部分重同步特性会用到一个新增的PSYNC内部命令， 而redis 2.8以前的旧版本只有SYNC命令，不过只要从服务器是redis 2.8或以上的版本， 它就会根据主服务器的版本来决定到底是使用PSYNC还是SYNC：
如果主服务器是redis 2.8或以上版本，那么从服务器使用PSYNC命令来进行同步
如果主服务器是redis 2.8之前的版本，那么从服务器使用SYNC命令来进行同步

配置一个从服务器非常简单，只要在配置文件中增加以下的这一行就可以了：
slaveof 192.168.1.1 6379
当然，你需要将代码中的192.168.1.1和6379替换成你的主服务器的IP和端口号
另外一种方法是调用SLAVEOF命令，输入主服务器的IP和端口，然后同步就会开始：
127.0.0.1:6379> SLAVEOF 192.168.1.1 10086
OK

从redis 2.6开始， 从服务器支持只读模式，并且该模式为从服务器的默认模式
只读模式由redis.conf文件中的slave-read-only选项控制， 也可以通过CONFIG SET命令来开启或关闭这个模式
只读从服务器会拒绝执行任何写命令， 所以不会出现因为操作失误而将数据不小心写入到了从服务器的情况
即使从服务器是只读的，DEBUG和CONFIG等管理式命令仍然是可以使用的， 所以我们还是不应该将服务器暴露给互联网或者任何不可信网络， 不过，使用redis.conf中的命令改名选项， 我们可以通过禁止执行某些命令来提升只读从服务器的安全性
你可能会感到好奇， 既然从服务器上的写数据会被重同步数据覆盖，也可能在从服务器重启时丢失，那么为什么要让一个从服务器变得可写呢？
原因是，一些不重要的临时数据，仍然是可以保存在从服务器上面的。比如说，客户端可以在从服务器上保存主服务器的可达性信息， 从而实现故障转移策略

如果主服务器通过requirepass选项设置了密码， 那么为了让从服务器的同步操作可以顺利进行，我们也必须为从服务器进行相应的身份验证设置
对于一个正在运行的服务器，可以使用客户端输入以下命令：
CONFIG SET masterauth <password>
要永久地设置这个密码，那么可以将它加入到配置文件中：
masterauth <password>

键空间通知
键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了Redis数据集的事件

以下是一些键空间通知发送的事件的例子：
所有修改键的命令
所有接收到LPUSH命令的键
0号数据库中所有已过期的键
事件通过redis的订阅与发布功能（pub/sub）来进行分发，因此所有支持订阅与发布功能的客户端都可以在无须做任何修改的情况下，直接使用键空间通知功能
因为Redis目前的订阅与发布功能采取的是发送即忘（fire and forget）策略，所以如果你的程序需要可靠事件通知（reliable notification of events），那么目前的键空间通知可能并不适合你： 当订阅事件的客户端断线时，它会丢失所有在断线期间分发给它的事件
对于每个修改数据库的操作，键空间通知都会发送两种不同类型的事件
比如说，对0号数据库的键mykey执行DEL命令时，系统将分发两条消息，相当于执行以下两个PUBLISH命令：

PUBLISH __keyspace@0__:mykey del
PUBLISH __keyevent@0__:del mykey
订阅第一个频道 __keyspace@0__:mykey可以接收0号数据库中所有修改键mykey的事件， 而订阅第二个频道 __keyevent@0__:del则可以接收0号数据库中所有执行del命令的键

以keyspace为前缀的频道被称为键空间通知（key-space notification），而以keyevent为前缀的频道则被称为键事件通知（key-event notification）
当del mykey命令执行时：
键空间频道的订阅者将接收到被执行的事件的名字，在这个例子中，就是del 
键事件频道的订阅者将接收到被执行事件的键的名字，在这个例子中，就是mykey 
未来将会支持更可靠的事件分发，这种支持可能会通过让订阅与发布功能本身变得更可靠来实现，也可能会在Lua脚本中对消息（message）的订阅与发布进行监听，从而实现类似将事件推入到列表这样的操作
因为开启键空间通知功能需要消耗一些CPU，所以在默认配置下，该功能处于关闭状态

可以通过修改redis.conf文件，或者直接使用CONFIG SET命令来开启或关闭键空间通知功能：

当notify-keyspace-events选项的参数为空字符串时，功能关闭，当参数不是空字符串时，功能开启
notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：
字符发送的通知
K	键空间通知，所有通知以 __keyspace@<db>__ 为前缀
E	键事件通知，所有通知以 __keyevent@<db>__ 为前缀
g	DEL 、EXPIRE 、RENAME等类型无关的通用命令的通知
$	字符串命令的通知
l	列表命令的通知
s	集合命令的通知
h	哈希命令的通知
z	有序集合命令的通知
x	过期事件：每当有过期键被删除时发送
e	驱逐(evict)事件：每当有键因为maxmemory配置而被删除时发送
A	参数g$lshzxe的别名
输入的参数中至少要有一个K或者E，否则的话，不管其余的参数是什么，都不会有任何通知被分发
举个例子，如果只想订阅键空间中和列表相关的通知，那么参数就应该设为Kl ， 诸如此类
将参数设为字符串 "AKE" 表示发送所有类型的通知

redis版本相关
redis是一个保存用户数据的软件，所以这是最需要严格对待的一类
因此，我们会在redis到了具有很高级别稳定性时才会发布新版本，即使代价是版本更新的速度很慢
redis有以下集中版本：
1，非稳定版
2，开发版
3，冻结版
4，发布候选版
5，稳定版

非稳定版分支
非稳定版的分支基本都在github上
非稳定版会包括很多正在开发，还未考虑加入的新特性，可能包括很严重的bug
但是我们仍然会努力使非稳定版能够在开发环境中的大多数时间尽可能的工作正常

冻结版，发布候选版
当计划有一个新版本的时候，非稳定版会分出一个分支，其名字就是将来需要发布的版本
新的分支会在稳定性分为三个版本：开发版，冻结版和开发候选版
开发版：新特性和bug修复会提交至分支，但是并不是所有在非稳定版中的都会合并至此分支，只有在此特性能够在合理的时间规划内满足稳定性要求才能提交
冻结版：不会有新特性的加入，除非此特定对稳定性无影响，并且此特性很重要需要尽快提交至分支，仅仅在需要修复bug时才能被提交至分支
发布候选版：仅允许bug修复的代码提交

稳定版
在某个时间，我们会将发布后选版中选择一个版本，并观察严重bug的数量是否在减少，如果几周后没有严重bug出现，那么我们会标记此版本为稳定版
稳定版版本号也是通常的主版本.次版本.修正版本号这样的形式
1，次版本号为偶数时表示是稳定版
2，次版本号为基数时表示时非稳定版，开发版，冻结版或则是发布候选版
3，修正版本号会随着bug的修复而逐渐增加，当某个版本成为发布预览版后，修正版本号从101开始递增

技术支持
由于我们会尽可能的保证redis的api的向后兼容性，所以不会对老版本提供技术支持，升级到新版本
例如，如果现在的稳定版是2.6.X，那么我们会为之前的稳定版即2.4.X接受bug报告并提供支持，但不支持2.2.X版本
当2.8成为稳定版后，2.6.X会变成提供支持的最旧版本

redis客户端处理
redis通过TCP/IP或者Unix的Sock文件与服务器进行通信，当一个新的连接到达服务端时，会有以下操作：
1，客户端的socket文件会处于在非阻塞状态中，因为redis使用multiplex和非阻塞I/O
2，TCP_NODELAY会被设置，以保证连接过程中不会有延迟现象
3，一个可读的文件会被创建，以保证redis可以在数据到达socket文件后就立即能够收集客户端的请求

在连接初始化之后，redis还会查看是否已经到达连接上限，如果此时已到达上限，redis会返回客户端一个错误，并立刻关闭连接

客户端的请求是如何被处理的
1，为了保证在有多个客户端连接，有的客户端请求的速率高而导致其他客户端不会有很大延迟，redis每次会调用单个的read()系统调用来从client的socket文件在中读取数据
2，一旦从客户端读取了数据，那么所有位于当前的缓冲区中的请求都会被顺序的处理，这样可以避免再去查看是否有客户端需要处理

最大连接的客户端数
此配置用来限制能够连接redis的最大客户端数，此配置也和系统的打开文件数目相关
如果需要配置此值，那么应该将系统打开文件数一并进行调整
ulimit -Sn 100000
sysctl -w fs.file-max=100000

输出缓冲区限制
redis会为每一个客户端保持一个缓冲区，在某些情况下，例如：pub/sub，客户端很有可能没有办法处理服务端发送的请求，这样会导致redis申请更多的内存来作为缓冲区
为了避免这个现象，redis会针对不同的客户端限制输出缓冲区的大小
硬限制是一个固定的上限值，一旦到达这个值，redis会立刻断开和客户端的连接
软限制是一个基于时间的值，例如：32MB每10s，意味着如果redis为某个客户端维持了32MB的缓冲区长达10s，那么redis会断开此客户端的链接

对于不同的客户端，其限制也不同
一般客户端：无限制，由于普通客户端使用阻塞的方式来发送请求并等待响应然后完成读取，所以不需要限制缓冲区大小
pub/sub客户端：默认硬上限为32mb，软上线为8mb每60s
从服务器：默认硬上限为256mb，软上线为64mb每60s

请求缓冲区限制
如果一个客户端的请求缓冲区到达1GB上线，那么此客户端的连接将会被断开，此上限不可配置

客户端超时
默认情况下，redis不会关闭已经空闲了一段时间的连接，就意味着连接会永远打开
但是如果你不喜欢这样的默认行为，你可以设置一个超时时间，所以一旦客户端的空闲时间超过此限制，那么客户端的连接就会被断开
注意此配置只对一般的客户端生效，对于pub/sub客户端不生效，因为pub/sub客户端需要保持在空闲状态中等待推送消息
超时时间并不会和配置的完全相同，redis会避免设置计时器或者是运行O(n)复杂度的算法来检测客户端，而是在某个时间的基础上来进行计算，所以当时设置为10s时，如果有很多客户端同时连接，可能在12s之后才会断开连接

测试工具
redis会内置一个测试工具redis-benchmark，可以模拟N个客户端同时发送M个请求（类似apache的ab工具），以下是使用方法：
Usage: redis-benchmark [-h <host>] [-p <port>] [-c <clients>] [-n <requests]> [-k <boolean>]

 -h <hostname>      Server hostname (default 127.0.0.1)
 -p <port>          Server port (default 6379)
 -s <socket>        Server socket (overrides host and port)
 -c <clients>       Number of parallel connections (default 50)
 -n <requests>      Total number of requests (default 10000)
 -d <size>          Data size of SET/GET value in bytes (default 2)
 -k <boolean>       1=keep alive 0=reconnect (default 1)
 -r <keyspacelen>   Use random keys for SET/GET/INCR, random values for SADD
  Using this option the benchmark will get/set keys
  in the form mykey_rand:000000012456 instead of constant
  keys, the <keyspacelen> argument determines the max
  number of values for the random number. For instance
  if set to 10 only rand:000000000000 - rand:000000000009
  range will be allowed.
 -P <numreq>        Pipeline <numreq> requests. Default 1 (no pipeline).
 -q                 Quiet. Just show query/sec values
 --csv              Output in CSV format
 -l                 Loop. Run the tests forever
 -t <tests>         Only run the comma-separated list of tests. The test
                    names are the same as the ones produced as output.
 -I                 Idle mode. Just open N idle connections and wait.
 
可以通过-t来指定测试的命令：
例如：redis-benchmark -t set,lpush -n 100000 -q

也可以通过指定脚本来测试：
例如：redis-benchmark -n 100000 -q script load "redis.call('set','foo','bar')"

可以通过-r来指定使用一定数量的随机值完成测试
例如：redis-benchmark -t set -r 100000 -n 1000000

可以通过pipeline来测试，由于pipeline是将所有的请求一次发送，所以相对来说性能更好
redis-benchmark -n 1000000 -t set,get -P 16 -q

陷阱和一些误解
核心：基准测试的黄金定律是苹果和苹果来比较，例如不同版本的redis可以拿来相互比较，或者是相同版本不同选项的redis
1，redis是一个服务器，所有的命令都牵扯到网络或者IPC，没有必要和SQLite，Berkeley DB，Tokyo/Kyoto Cabinet来进行比较，因为真正影响的是网络和协议管理方面的因素
2，redis的所有命令都会返回一个确认，有一些数据存储技术不会返回确认，在考虑到使用redis作为单项请求的，相对于其他的存储技术，redis有一些优势
3，原生的同步命令不会测试redis的本身，会测试到网络或者IPC的延迟，需要真正的测试redis，需要与redis的server建立多个连接，或者是使用pipeline来将若干个命令组合在一起或者以多线程的模式来进行
4，redis是一个基于内存的具有持久化功能的存储，如果你希望和事务性存储（MySQL，PostgreSQL等），你应当考虑开启AOF并确定一个合适的fsync()
5，redis是一个单进程的模型，在其设计之初就不是为了支持多个CPU而开发的，很多人会开启多个redis实例并绑定在不同的核心上，但是这样与一个真正多线程服务器相比是不公平的

一个核心的误解是redis-benchmark工具是用来查看redis的主要性能表现，但是redis-benchmark的请求都是人造的，与真正的环境相差很大

影响redis性能表现的因素
1，网络带宽和延迟，可以通过ping对网络延迟做简单测试，在很多情况下，网络的带宽和延迟是限制redis性能的主要因素，在测试时也应该基于带宽来设置请求的数量和大小
2，CPU，由于redis是单进程模型，运行越快，缓存越大的CPU会让redis运行的更快，但是更多的核心并不会有提升，Intel的CPU表现强于AMD的
3，内存速度和内存带宽，但是相对于前两者，此因素对于redis性能的影响不是特别大，所以为了redis购买更好的内存并不一定会有很大提升
4，unix的sock文件和tcp/ip环回口，在相同的环境中，使用unix的sock文件可以有接近50%的提升相对于使用tcp/ip环回口的情况
5，在使用大量的pipeline时，以上优势不复存在，使用unix的sock文件使得性能下降的较快
6，在使用pipeline将命令组合在一起时，如果数据大小大于以太网最大帧大小时，性能下降的很快
7，多CPU服务器，redis的性能表现取决于NUMA的配置以及进程的位置
8，连接的客户端数目也是一个重要的因素，得益于epoll和kqueue，redis在接受了60000个以上连接时表现都很不错，但是在接受了30000个连接后，redis的性能已经下降了一半
9，网卡配置和关联中断，最好是将网卡的进向出向队列和CPU核心做关联，并开启RPS支持
10，平台自身，redis可以根据平台不同而在编译时使用不同的内存分配器，这些分配器的差异可能会影响redis的性能表现，可以通过INFO来查看是使用哪一个内存分配器

redis的Sentinel系统用于管理多个redis服务器（instance），该系统执行以下三个任务：
监控（Monitoring）：Sentinel会不断地检查你的主服务器和从服务器是否运作正常
提醒（Notification）：当被监控的某个redis服务器出现问题时，Sentinel可以通过API向管理员或者其他应用程序发送通知
自动故障迁移（Automatic failover）：当一个主服务器不能正常工作时，Sentinel会开始一次自动故障迁移操作，它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器；当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址，使得集群可以使用新主服务器代替失效服务器
Redis Sentinel 是一个分布式系统，你可以在一个架构中运行多个Sentinel进程（progress）， 这些进程使用流言协议（gossip protocols)来接收关于主服务器是否下线的信息， 并使用投票协议（agreement protocols）来决定是否执行自动故障迁移，以及选择哪个从服务器作为新的主服务器

虽然Redis Sentinel释出为一个单独的可执行文件redis-sentinel ， 但实际上它只是一个运行在特殊模式下的Redis服务器， 你可以在启动一个普通Redis服务器时通过给定 --sentinel选项来启动Redis Sentinel

对于 redis-sentinel 程序，你可以用以下命令来启动Sentinel系统：
redis-sentinel /path/to/sentinel.conf
对于 redis-server 程序，你可以用以下命令来启动一个运行在Sentinel模式下的 Redis 服务器：
redis-server /path/to/sentinel.conf --sentinel

如果启动Sentinel时没有指定相应的配置文件， 或者指定的配置文件不可写（not writable）， 那么Sentinel会拒绝启动

源码中包含了一个名为sentinel.conf的文件， 这个文件是一个带有详细注释的Sentinel配置文件示例。

运行一个Sentinel所需的最少配置如下所示：
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 60000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1
sentinel monitor resque 192.168.1.3 6380 4
sentinel down-after-milliseconds resque 10000
sentinel failover-timeout resque 180000
sentinel parallel-syncs resque 5

第一行配置指示Sentinel去监视一个名为mymaster的主服务器， 这个主服务器的IP地址为127.0.0.1，端口号为6379，而将这个主服务器判断为失效至少需要2个Sentinel同意 （只要同意Sentinel的数量不达标，自动故障迁移就不会执行）
不过要注意，无论你设置要多少个Sentinel同意才能判断一个服务器失效， 一个Sentinel都需要获得系统中多数（majority）Sentinel的支持，才能发起一次自动故障迁移，并预留一个给定的配置纪元（configuration Epoch ，一个配置纪元就是一个新主服务器配置的版本号）
换句话说， 在只有少数（minority）Sentinel进程正常运作的情况下，Sentinel是不能执行自动故障迁移的

redis的Sentinel中关于下线（down）有两个不同的概念：
主观下线（Subjectively Down， 简称SDOWN）指的是单个Sentinel实例对服务器做出的下线判断。
客观下线（Objectively Down， 简称 ODOWN）指的是多个Sentinel实例在对同一个服务器做出SDOWN判断， 并且通过SENTINEL is-master-down-by-addr命令互相交流之后， 得出的服务器下线判断 一个Sentinel可以通过向另一个Sentinel发送SENTINEL is-master-down-by-addr命令来询问对方是否认为给定的服务器已下线

从主观下线状态切换到客观下线状态并没有使用严格的法定人数算法（strong quorum algorithm），而是使用了流言协议： 如果Sentinel在给定的时间范围内， 从其他Sentinel那里接收到了足够数量的主服务器下线报告，那么 Sentinel 就会将主服务器的状态从主观下线改变为客观下线。如果之后其他Sentinel不再报告主服务器已下线，那么客观下线状态就会被移除
客观下线条件只适用于主服务器： 对于任何其他类型的redis实例，Sentinel在将它们判断为下线前不需要进行协商， 所以从服务器或者其他Sentinel永远不会达到客观下线条件
只要一个Sentinel发现某个主服务器进入了客观下线状态， 这个Sentinel就可能会被其他Sentinel推选出， 并对失效的主服务器执行自动故障迁移操作

每个Sentinel 都需要定期执行的任务
每个Sentinel以每秒钟一次的频率向它所知的主服务器、从服务器以及其他Sentinel实例发送一个PING命令
如果一个实例（instance）距离最后一次有效回复PING命令的时间超过down-after-milliseconds选项所指定的值，那么这个实例会被Sentinel标记为主观下线。
一个有效回复可以是：+PONG、-LOADING或者-MASTERDOWN
如果一个主服务器被标记为主观下线，那么正在监视这个主服务器的所有Sentinel要以每秒一次的频率确认主服务器的确进入了主观下线状态
如果一个主服务器被标记为主观下线，并且有足够数量的Sentinel（至少要达到配置文件指定的数量）在指定的时间范围内同意这一判断， 那么这个主服务器被标记为客观下线
在一般情况下，每个Sentinel会以每10秒一次的频率向它已知的所有主服务器和从服务器发送INFO命令。当一个主服务器被Sentinel标记为客观下线时，Sentinel向下线主服务器的所有从服务器发送 INFO 命令的频率会从10 秒一次改为每秒一次
当没有足够数量的 Sentinel 同意主服务器已经下线，主服务器的客观下线状态就会被移除。当主服务器重新向Sentinel的PING命令返回有效回复时，主服务器的主管下线状态就会被移除

一个Sentinel可以与其他多个Sentinel进行连接，各个Sentinel之间可以互相检查对方的可用性，并进行信息交换
你无须为运行的每个Sentinel分别设置其他Sentinel的地址，因为Sentinel可以通过发布与订阅功能来自动发现正在监视相同主服务器的其他Sentinel，这一功能是通过向频道 __sentinel__:hello 发送信息来实现的
与此类似， 你也不必手动列出主服务器属下的所有从服务器，因为Sentinel可以通过询问主服务器来获得所有从服务器的信息

每个Sentinel会以每两秒一次的频率， 通过发布与订阅功能，向被它监视的所有主服务器和从服务器的 __sentinel__:hello 频道发送一条信息，信息中包含了Sentinel的IP地址、端口号和运行ID（runid）
每个Sentinel都订阅了被它监视的所有主服务器和从服务器的 __sentinel__:hello 频道，查找之前未出现过的Sentinel（looking for unknown sentinels）
当一个Sentinel发现一个新的Sentinel时，它会将新的Sentinel添加到一个列表中， 这个列表保存了Sentinel已知的， 监视同一个主服务器的所有其他Sentinel
Sentinel发送的信息中还包括完整的主服务器当前配置（configuration）。 如果一个Sentinel包含的主服务器配置比另一个Sentinel发送的配置要旧， 那么这个Sentinel会立即升级到新配置上
在将一个新Sentinel添加到监视主服务器的列表上面之前，Sentinel会先检查列表中是否已经包含了和要添加的Sentinel拥有相同运行ID或者相同地址（包括IP地址和端口号）的Sentinel，如果是的话， Sentinel会先移除列表中已有的那些拥有相同运行ID或者相同地址的Sentinel，然后再添加新的Sentinel

一次故障转移操作由以下步骤组成：
发现主服务器已经进入客观下线状态
对我们的当前纪元进行自增（详情请参考 Raft leader election），并尝试在这个纪元中当选
如果当选失败， 那么在设定的故障迁移超时时间的两倍之后， 重新尝试当选，如果当选成功，那么执行以下步骤
选出一个从服务器，并将它升级为主服务器。
向被选中的从服务器发送SLAVEOF NO ONE命令，让它转变为主服务器
通过发布与订阅功能，将更新后的配置传播给所有其他Sentinel，其他Sentinel对它们自己的配置进行更新
向已下线主服务器的从服务器发送SLAVEOF命令， 让它们去复制新的主服务器
当所有从服务器都已经开始复制新的主服务器时， 领头 Sentinel 终止这次故障迁移操作
每当一个redis实例被重新配置（reconfigured） —— 无论是被设置成主服务器、从服务器、又或者被设置成其他主服务器的从服务器 —— Sentinel都会向被重新配置的实例发送一个CONFIG REWRITE 命令， 从而确保这些配置会持久化在硬盘里

Sentinel 使用以下规则来选择新的主服务器：
在失效主服务器属下的从服务器当中， 那些被标记为主观下线、已断线、或者最后一次回复PING命令的时间大于五秒钟的从服务器都会被淘汰
在失效主服务器属下的从服务器当中， 那些与失效主服务器连接断开的时长超过down-after选项指定的时长十倍的从服务器都会被淘汰
在经历了以上两轮淘汰之后剩下来的从服务器中， 我们选出复制偏移量（replication offset）最大的那个从服务器作为新的主服务器；如果复制偏移量不可用，或者从服务器的复制偏移量相同， 那么带有最小运行ID的那个从服务器成为新的主服务器

Sentinel自动故障迁移的一致性特质
Sentinel自动故障迁移使用Raft算法来选举领头（leader）Sentinel，从而确保在一个给定的纪元（epoch）里， 只有一个领头产生
这表示在同一个纪元中，不会有两个Sentinel同时被选中为领头， 并且各个Sentinel在同一个纪元中只会对一个领头进行投票
更高的配置纪元总是优于较低的纪元，因此每个Sentinel都会主动使用更新的纪元来代替自己的配置
简单来说，我们可以将Sentinel配置看作是一个带有版本号的状态，一个状态会以最后写入者胜出（last-write-wins）的方式（也即是，最新的配置总是胜出）传播至所有其他Sentinel
举个例子，当出现网络分割（network partitions）时，一个Sentinel可能会包含了较旧的配置， 而当这个Sentinel接到其他Sentinel发来的版本更新的配置时，Sentinel 就会对自己的配置进行更新。
如果要在网络分割出现的情况下仍然保持一致性，那么应该使用min-slaves-to-write选项，让主服务器在连接的从实例少于给定数量时停止执行写操作，与此同时，应该在每个运行redis 主服务器或从服务器的机器上运行 Redis Sentinel 进程

Sentinel状态的持久化
Sentinel的状态会被持久化在Sentinel配置文件里面
每当 Sentinel 接收到一个新的配置，或者当领头Sentinel为主服务器创建一个新的配置时，这个配置会与配置纪元一起被保存到磁盘里面
这意味着停止和重启 Sentinel 进程都是安全的
Sentinel在非故障迁移的情况下对实例进行重新配置
即使没有自动故障迁移操作在进行，Sentinel总会尝试将当前的配置设置到被监视的实例上面。 特别是：
根据当前的配置，如果一个从服务器被宣告为主服务器，那么它会代替原有的主服务器，成为新的主服务器，并且成为原有主服务器的所有从服务器的复制对象
那些连接了错误主服务器的从服务器会被重新配置，使得这些从服务器会去复制正确的主服务器
不过，在以上这些条件满足之后，Sentinel在对实例进行重新配置之前仍然会等待一段足够长的时间， 确保可以接收到其他Sentinel发来的配置更新， 从而避免自身因为保存了过期的配置而对实例进行了不必要的重新配置

redis分区
分区就是讲数据划分到多个redis实例中，所以每个实例会包括所有数据的一部分

分区的用处
1，可以使用多台服务器的内存来存储一个大的数据库，如果不使用分区，那么数据库的大小会被物理内存限制
2，可以扩展使用的资源，例如多核CPU，多台服务器，多台网络设备和服务器之间的带宽

基础
想象一下，我们有R0，R1，R2和R3一共4个redis实例，以及很多key，我们可以发现有很多办法来选择将key存入哪一个示例
换句话说，有很多办法将一个给定的key映射到一个给定的redis服务器
最简单的方法是通过范围来进行分区，就是通过将一定范围内的key映射到一个指定的redis实例。这样的模式可以工作的很好
但是需要一个映射表来维护映射关系，这样的劣势在于这张表需要管理，每个不同的对象都需要不同的表，所以很多情况下，相对于其他的方式，使用范围来分区其实效率更不好
另外一种是hash分区，这样的分区方式不需要类似有范围的id，只需要通过key和一个hash函数来得到一个数字，然后用取模的方式
来得到一个0到3之间的值，所以可以被映射到4个redis的实例中
还存在很多其他方式的分区方法，但是以上两种实例应该能够明白分区的工作原理，有一个更高级的hash分区方法叫做一致性hash
很多redis的客户端和proxy都使用了这种方法

分区的实现方式
1，客户端分区意味着客户端直接选择正确的实例来读写一个key，很多redis的client实现了客户端分区
2，代理辅助分区意味着客户端发送请求至可以跟redis服务器通信的代理，而不是直接将请求发送至redis实例，代理会根据配置的分区方法将请求发送至正确的服务器，并将响应发送给redis客户端
3，请求路由意味着可以将请求发送至一个随机的服务器，而且这个实例会转发请求至正确的服务器，redis的cluster实现了一个混合的请求路由方式

分区的劣势
1，涉及多个key的操作通常是不支持的
2，涉及多个key的事务不支持
3，分区的粒度是key，所以不能切分一个很长的单个的key至多个实例
4，使用了分区后，数据的处理会变得更复杂
5，添加和缩减实例会非常复杂，redis的cluster支持在增加或者移除节点是透明的重新分配数据的功能，但是大多数的客户端不支持这个特性

数据存储还是缓存
如果redis被用来当做缓存，并需要做横向或者纵向扩展，那么就是用一致性hash
如果redis被用来当做数据存储，那么应该使用固定的key到节点的映射的方式，所以节点的数量必须是固定的并且不能变化，否则需要一个在增加或移除节点时重新分配key和node的系统，redis的cluster可以实现这个功能

预先分区
由于数据存储的状况随时都在发生变化，今天可能有10个redis实例，明天就可能变为50个，由于redis是一个轻量级的服务，那么即使在一开始仅有一台服务器的时候就预先使用分布式的结构进行预先分区，即在单台服务器上使用多个实例并进行分区
当数据存储的需要增加redis服务器的时候，就可以将部分实例迁移到其他的服务器上
使用redis的复制可以很方便的实现迁移，仅需要很少的停服时间：
1，在新的服务器上开启一个新的空实例
2，将配置应用至新实例，并配置为旧实例的从服务器
3，停止客户端
4，更新新实例的配置，修改新实例的IP地址
5，发送SLAVEOF NO ONE至新实例
6，开启客户端
7，最终关闭旧的不使用的实例

redis分区的实现
1，redis的cluster
2，Twemproxy
3，支持一致性hash的客户端分区

使用redis作为一个LRU缓存
当redis被作为一个缓存来使用时，redis应该在增加了新数据时丢弃旧数据，这是为人所知的memcached系统的默认行为
实际上redis支持的是一个近似LRU的的key丢弃方式
在将redis当做缓存来使用时，需要注意的是配置一个固定的内存值以及key丢弃方式

最大内存
最大内存是用来限定redis可以使用的最大内存，设置为0时表示无限制，在64bit系统上默认为0，即不限制

丢弃策略
volatile-lru : 使用LRU算法来删除设置了超时的key
allkeys-lru : 根据LRU算法删除任意key
volatile-random : 随机删除设置了超时的key
allkeys-random : 随机删除任意key
volatile-ttl : 删除距离超时时间最近的key
noeviction : 不删除，在有写入操作时返回错误

如果有一部分数据的访问频率比其他的数据频繁的话，应该使用allkeys-lru策略
如果当所有的数据需要循环访问或者所有的数据都以正常的概率被访问，应该使用allkeys-random策略
如果想在设置了超时时间的某些候选的数据中进行选择，应该使用volatile-ttl策略

allkeys-lru和volatile-random策略是在单实例的redis服务中最有用的两个策略

需要记住的是为数据设置超时时间也需要消耗内存，所以allkeys-lru会更有效的利用内存，因为不需要为每个key设置超时时间

分布式锁
分布式锁是一个在很多环境中非常有用的原语，它是不同进程互斥操作共享资源的唯一方法。有很多的开发库和博客描述如何使用redis实现DLM（Distributed Lock Manager），但是每个开发库使用了不同的方式，而且相对于更复杂的设计与实现来说，很多使用一些简单低但是低可靠的方式来实现。 

这篇文档提供了一个更权威的算法来实现分布式锁。我们提出了一个算法叫做RedLock，相对于vanilla单实例的方法更加安全的分布式锁管理。我们希望社区能够对RedLock进行分析并提出改进，并且作为实现或者其他更复杂设计的起点。

实现
Redlock-rb (Ruby实现)
Redlock-py (Python实现)
Redlock-php (PHP实现)
Redsync.go (Go实现)
redisson (Java实现)
redis::DistLock (Perl实现)
Redlock-cpp (Cpp实现)
Redlock-cs (C#/.NET实现)

从有效分布式锁的最小保证粒度来说，我们的模型里面只用了3个属性，具体如下：
1. 安全属性：互斥行，在任何时候，只有一个客户端可以获得锁
2. 活跃属性A：死锁自由，即使一个客户端已经拥用了已损坏或已被分割资源的锁，但它也有可能请求其他的锁
3. 活跃属性B：容错，只要大部分redis节点可用， 客户端就可以获得和释放锁

为何基于容错的实现还不够
要理解我们所做的改进，就要先分析下当前基于redis的分布式锁的做法。
使用redis对资源加锁的最简单的方法是创建一对key-value值。利用redis的超时机制，key被创建为有一定的生存期，因此它最终会被释放，而当客户端想要释放时，直接删除key就可以

一般情况下这种方法会工作得很好，但有个问题：这是系统的一个单点故障。如果redis主节点不可用呢个？当然，我们可以增加子节点，在主节点出问题时可以切换至从节点。但是这种方案不可行，因为redis的主从复制是异步的，我们无法用其实现互斥的安全特性。

这明显是该模型的一种竞态条件：
客户端A在主节点获得了一个锁。
主节点不可用，而到从节点的写同步还没完成。
从节点被提升为主节点。
客户端B获得和A相同的锁。注意，锁安全性被破坏了。

有时候，在某些情况下这反而工作得很好，例如在出错时，多个客户端可以获得同一个锁。如果这正好是你想要的，那就可以使用主从复制的方案。否则，我们建议使用这篇文章中描述的方法。

单实例的正确实现方案
在尝试解决上述的单实例方案的缺陷之前，先让我们确保针对这种简单的情况下怎么做才是正确的，因为这种方案对某些程序来说也是可以接受的，而且这也是我们即将描述的分布式方案的基础。

为了获取锁，可以通过以下方式：
SET resource_name my_random_value NX PX 30000
这条指令将设置key的值，仅当其不存在时生效(NX选项), 且设置其生存期为30000毫秒。和key关联的value值是"my_random_value"。这个值在所有客户端和所有加锁请求中是必须是唯一的。
使用随机值主要是为了能够安全地释放锁，这要同时结合这样的处理逻辑：删除key值当且仅当其已存在并且其value值是我们所期望的。请看以下lua代码：

if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end

这么做很重要，因为这样可以避免误删其他客户端创建的锁。例如某个客户端获得了一个锁，但它的处理时长超过了锁的有效时长，之后它删除了这个锁，而此时这个锁可能又被其他客户端获得。所以仅仅做删除是不够安全的，很可能会把其他客户端的锁删除。结合上面的代码，每个锁都有个唯一的随机值，因此仅当这个值依旧是客户端所设置的值时才会去删除它。
那么应该怎样生成这个随机值呢？我们可以从/dev/urandom读取的20个字节，但也有更简单的方法，只要能实现就可以。例如，可以使用/dev/urandom来初始化RC4算法，然后用其产生随机数流。更简单的方法是组合unix时间戳和客户端ID，这并不安全，但对很多环境而言也够用了。

我们所说的key的时间，是指”锁的有效时长“。它代表两种情况，一种是指锁的自动释放时长，另一种是指在另一个客户端获取锁之前某个客户端占用这个锁的时长。
现在我们已经有好的办法获取和释放锁了。在单实例非分布式系统中只要保证节点可用，这个方法就是安全的。

Redlock 算法
在此算法的分布式版本中，我们假设有N个redis主节点。这些节点是相互独立的，因此我们不使用复制或其他隐式同步机制。我们知道在单实例情况下如何安全地获取锁。我们也指出此算法将使用这种方法从单实例获取和释放锁。在以下示例中，我们设置N=5（比较适中的值），这样我们需要在不同物理机或虚拟机上运行5个redis主节点，以确保它们的出错是尽可能独立的。
为了获取锁，客户端执行以下操作：
获取当前时间，以毫秒为单位
以串行的方式尝试从所有的N个实例中获取锁，使用的是相同的key值和相同的随机value值。在从每个实例获取锁时，客户端会设置一个连接超时，其时长相比锁的自动释放时间要短得多。例如，若锁的自动释放时间是10秒，那么连接超时大概设在5到50毫秒之间。这可以避免当redis节点不可用时，会长时间阻塞客户端：如果某个节点没有及时响应，就应该尽快转到下个节点。
客户端计算获取所有锁耗费的时长，方法是使用当前时间减去步骤1中的时间戳。当且仅当客户端能从多数节点（至少3个）中获得锁，并且耗费的时长小于锁的有效期时，可认为已经获得了锁。
如果获得了锁，它的最终有效时长将重新计算为其原时长减去步骤3中获取锁耗费的时长。
如果获取锁失败（要么是没有锁住N/2+1个节点，要么是锁的最终有效时长为负数），客户端会对所有实例进行解锁操作（即使对那些没有加锁成功的实例也一样）。

算法是异步的?
算法依赖于这样一个假定，它在处理的时候不是基于同步时钟的，每个处理中仍然使用的是本地的时间，它只是大致地以同样地速率运行，这样它就会有一个小的误差，与之相比会有一个小的自动开合的时钟时间。这个假设很像真正世界的电脑：每一台电脑有一个本地时间，通常我们使用不同的电脑会有一个很小的时间差。
基于这个观点，我们需要更好地指明我们共同的互斥法则：这是保证客户端能长时间保持状态锁定，其将会终止它们在有效时间内的工作（在步骤3中获得），减去一些时间（在处理时时间差时减去了一些毫秒用来补偿）。

失败时重试
当客户端无法获取锁时，它应该在一个随机延迟后重试，从而避免多个客户端同时试图获取锁。同样的，客户端在大多数场合下尝试获取锁的速度越快，重试的需要也越少，所以实际情况下客户端应尝试采用复用方式发送SET命令到多个实例。
强调客户在获取主锁失败是有意义的，释放（或部分）以尽快获得锁，这样没有必要为获取锁锁而去等待key到期（但是如果网络分区发生变化客户端不能与redis通信的情况下，需要显性提示和等待超时）。

释放锁
释放锁的实现很简单，只需要释放所有实例的锁即可，尽管客户端认为有能力成功锁住一个给出的实例。

安全参数
要问一个算法是否安全？那么可以尝试着去理解在不同的情景下发生了什么。我们以假设客户端在大多数情况下都能获得锁来开始，所有的实例都包含相同生存周期的键。由于键是在不同的时间设定的，所以键也将在不同的时间超时。然而，如果第一个节点最迟在t1时刻建立（接触的第一服务器之前），上一个键最迟在T2时刻建立（从上一个服务器获得回复的时间）。可以确定的是第一个键在超时之前将生存至少MIN_VALIDITY=TTL-(T2-T1)-CLOCK_DRIFT。所有其他的key将到期后，key将至少在这一次同时设置。
在过半的键被设置这段时间里，另一个客户端无法获得锁，如果N/2+1个键已经存在，N/2+1 SET NX操作将不能成功。所以一个锁被获取，同一时刻被重复获取是不可能的（违反互斥性）。
然而我们还想让多个客户端在获取锁的时候不能同时成功。
如果一个客户端锁定大部分实例的时间超过了锁的最大有效时间（TTL基本设定） ，它将认为锁无效，并释放锁。所以我们仅考虑在有效时间内大部分实例获得锁的情况。这种情况已经在上文中讨论过， 对于MIN_VALIDITY没有客户端会重新获取锁。所以只有当锁大多数实例的时间超过TTL时间时，多客户端才能同时锁住N/2+1个实例（在步骤2的“时间”即将结束时），让锁失效。 

存活性证明
系统的存活性基于以下三个主要特性：
锁的自动释放（key会到期）: 最终所有的key将可以被重新锁住
一般来说，客户端如果没有成功获得锁，或者获得了锁并且完成了工作，都会及时释放锁，使得我们无需等待key自动释放以重新获得。
当客户端重新获取锁之前，它会等待一段时间，这段时间比获取锁本身要长得多，这是为了尽量降低资源竞争引起的脑裂条件的概率。
然而，在网络割裂的情况下，我们得付出等同于"TTL"时间的可用性代价，如果网络持续割裂，我们就得无限的付出这个代价。这发生于当客户端获取了一个锁，而在删除锁之前网络断开了。
基本上，如果网络无限期地持续割裂，那系统将无限期地不可用。

性能、故障恢复和文件同步
许多用户使用redis作为一个需要高性能的加锁服务器，可以根据延迟动态的获取和释放锁，每秒可以成功执行大量的获取/释放锁操作。为了满足这些需求，一种多路复用策略是协同N台 redis服务器减少延迟（将端口置为non-blocking模式，发送所有的命令，延迟读出所有的命令，假定客户端和每个redis实例的往返时间是相似的）。
然而，如果我们旨在实现一种故障系统的恢复模式，这里有另一种与持久性相关的思路。
考虑这个基本问题，假定我们完全没有配置redis的持久性。一个客户端需要锁定5个实例中的3个。其中一个允许客户端获取的锁重新启动，虽然我们可以再次为一些资源锁定3个实例，但其它的客户端同样可以锁定它，违反了排他锁安全性。

如果我们启用AOF持久化，情况就会得到相当大的改善。例如我们可以通过发送 SHUTDOWN升级一个服务器并且重启它。因为redis的期限是通过语义设置的，所以服务器关闭的情况下虚拟时间仍然会流逝，我们所有的需求都得到了满足。不管怎样所有事务都会正常运转只要服务器完全关闭。如果电源中断会怎样？如果redis进行了相关配置，默认情况下每秒文件都会同步写入磁盘，很有可能在重启后我们的数据会丢失。理论上，如果我们想在任何一种实例重启后保证锁的安全性，我们需要确保在持久性配置中设置fsync=always。这将会在同等级别的CP系统上损失性能，传统上这种方式用来更安全的分配锁。

不管怎样事情比之前看起来好些。基本上算法的安全性得到保留，就算是当一个实例在故障后重启，它也将不再参与任何当前活跃的锁的分配。因此当实例重启时，当前所有活动锁的设置将从锁定的实例中获取除它重新加入系统。

为了保证这一点，我们只需要做一个实例，在超过最大TTL后不可用就需要时间去获取所有存在着的锁的key，当实例崩溃时，锁会被自动释放。
使用延时重启可以基本上保证安全，甚至不需要利用任何redis的持久化特性，但是这存在着另外的副作用。举例来说，如果大量的实例崩溃，系统变得全局不可用，那么TTL（这里的全局意味着根本就没有资源可用，在这个时间内所有的资源都会被锁定）。

让算法更可靠: 扩展锁
如果客户工作的执行是由小步骤组成，那么它就可以在默认时间里默认使用更小的锁，并扩展算法去实现的一个锁的扩展机制。当锁的有效性接近于一个低值，那么通常是客户端在运算中处于居中位置。当锁被取得时，可能扩展的锁通过发送一个Lua脚本到所有的实例，这个实例是扩展TTL的key，如果key存在，那么它的值就是客户端复制的随机值。
客户端应该仅考虑锁的重新取得，如果它可以被扩展，锁就会在有效时间内进入大量实例（基本的算法使用非常类似于获取锁的使用）。
虽然这不是从技术上去改变算法，但是无论如何尝试获取锁的最大次数是需要进行限制的，否则的话会违反活跃性中的一个属性。

大量插入数据
有时redis需要在很短的时间内载入大量的预先存在或者用户生成的数据，所以需要尽可能快的生成很大数量的keys，这个就叫做大量插入数据，这一部分的内容将会提供一些如何尽可能快的插入数据

使用协议，luke
使用传统的redis客户端来插入大量的数据并不是一个很好的想法：使用原始的方式发送请求是非常慢的，因为要等待每个命令的回程时间，可以使用pipeline，但是插入大量的数据需要编写很多新的命令，这样才能在收到核对回复的同时尽可能的插入大量的数据，只有少数的客户端支持非阻塞IO，而且并不是所有的客户端都能够很好的分片将请求发送至服务器以获得更大的吞吐量，由于以上的原因，最好的方式是生成一个文件，文件中包含所有插入数据的redis的原生命令

例如：我需要插入一个keyN -> ValueN格式的大量数据，那么需要的命令如下
SET Key0 Value0
SET Key1 Value1
...
SET KeyN ValueN

完成以上之后，需要做的就是尽可能快的发送至redis，过去可能会使用以下命令
(cat data.txt; sleep 10) | nc localhost 6379 > /dev/null

但是以上方法也不是特别可靠，因为netcat并不明确是否发送了所有数据也不能检查错误，而redis-cli提供了一个pipe模式
cat data.txt | redis-cli --pipe

会有以下输出：
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 1000000

生成redis协议
redis的协议非常容易生成和分片，在你需要利用redis的协议生成文件时并不需要理解所有的细节，每个命令的模式都如下：
*<args><cr><lf>
$<len><cr><lf>
<arg0><cr><lf>
<arg1><cr><lf>
...
<argN><cr><lf>

所以set key value的命令如下：
*3<cr><lf>
$3<cr><lf>
SET<cr><lf>
$3<cr><lf>
key<cr><lf>
$5<cr><lf>
value<cr><lf>

或者
"*3\r\n$3\r\nSET\r\n$3\r\nkey\r\n$5\r\nvalue\r\n"

所以插入大量数据的命令都可以按照以上形式，一个接一个

以下ruby函数可以完成以上操作：
def gen_redis_proto(*cmd)
    proto = ""
    proto << "*"+cmd.length.to_s+"\r\n"
    cmd.each{|arg|
        proto << "$"+arg.to_s.bytesize.to_s+"\r\n"
        proto << arg.to_s+"\r\n"
    }
    proto
end

puts gen_redis_proto("SET","mykey","Hello World!").inspect

使用以上函数，并以下面的方式，就可以生成以上例子中的所有命令
(0...1000).each{|n|
    STDOUT.write(gen_redis_proto("SET","Key#{n}","Value#{n}"))
}

然后就可以直接使用redis-cli来实现大量插入数据操作
$ ruby proto.rb | redis-cli --pipe
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 1000

redis的pipe模式的底层运作方式
pipe模式是需要和netcat一样快，并且可以理解收到的最新回复

这是通过以下方式来实现的：
redis-cli --pipe以尽可能快的方式将数据发送至服务器
与此同时读取数据，并分片
如果stdin中没有数据，会发送一个带有20个字节随机字符的ECHO命令，表示这是最后一个发送的命令，并在受到带有同样20个字节的回复时表示回复是可以匹配的
一旦这个发送了这个特殊命令，那么接受请求的代码会开始匹配回复中的20个字节的字符，如果匹配成功，那么将退出并返回成功

通过以上方式不需要将redis的协议进行分片来确定发送了多少个命令，只需要确定回复即可

集群简介
redis集群是一个可以在多个redis节点之间进行数据共享的设施
redis集群不支持那些需要同时处理多个键的 Redis 命令， 因为执行这些命令需要在多个 Redis 节点之间移动数据， 并且在高负载的情况下， 这些命令将降低redis集群的性能， 并导致不可预测的行为
redis集群通过分区来提供一定程度的可用性： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求

redis集群提供了以下两个好处：
将数据自动切分到多个节点的能力
当集群中的一部分节点失效或者无法进行通讯时， 仍然可以继续处理命令请求的能力

redis集群数据共享
redis集群使用数据分片而非一致性哈希来实现： 一个redis集群包含 16384 个哈希槽， 数据库中的每个键都属于这 16384 个哈希槽的其中一个， 集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和

集群中的每个节点负责处理一部分哈希槽。 举个例子， 一个集群可以有三个哈希槽， 其中：
节点 A 负责处理 0 号至 5500 号哈希槽
节点 B 负责处理 5501 号至 11000 号哈希槽
节点 C 负责处理 11001 号至 16384 号哈希槽
这种将哈希槽分布到不同节点的做法使得用户可以很容易地向集群中添加或者删除节点。 比如：
如果用户将新节点 D 添加到集群中， 那么集群只需要将节点 A 、B 、 C 中的某些槽移动到节点 D 就可以
与此类似， 如果用户要从集群中移除节点 A ， 那么集群只需要将节点 A 中的所有哈希槽移动到节点 B 和节点 C ， 然后再移除空白（不包含任何哈希槽）的节点 A 就可以
因为将一个哈希槽从一个节点移动到另一个节点不会造成节点阻塞， 所以无论是添加新节点还是移除已存在节点， 又或者改变某个节点包含的哈希槽数量， 都不会造成集群下线

redis集群中的主从复制
为了使得集群在一部分节点下线或者无法与集群的大多数节点进行通讯的情况下， 仍然可以正常运作， redis集群对节点使用了主从复制功能： 集群中的每个节点都有 1 个至 N 个复制品， 其中一个复制品为主节点， 而其余的 N-1 个复制品为从节点
在之前列举的节点 A 、B 、C 的例子中， 如果节点 B 下线了， 那么集群将无法正常运行， 因为集群找不到节点来处理 5501 号至 11000 号的哈希槽
另一方面， 假如在创建集群的时候（或者至少在节点 B 下线之前）， 我们为主节点 B 添加了从节点 B1 ， 那么当主节点 B 下线的时候， 集群就会将 B1 设置为新的主节点， 并让它代替下线的主节点 B ， 继续处理 5501 号至 11000 号的哈希槽， 这样集群就不会因为主节点 B 的下线而无法正常运作，不过如果节点 B 和 B1 都下线的话， Redis 集群还是会停止运作

redis集群的一致性保证
redis集群不保证数据的强一致性： 在特定条件下， Redis 集群可能会丢失已经被执行过的写命令。

使用异步复制是redis集群可能会丢失写命令的其中一个原因。 考虑以下这个写命令的例子：
客户端向主节点 B 发送一条写命令
主节点 B 执行写命令，并向客户端返回命令回复
主节点 B 将刚刚执行的写命令复制给它的从节点 B1 、 B2 和 B3 
如你所见， 主节点对命令的复制工作发生在返回命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 那么主节点处理命令请求的速度将极大地降低 —— 我们必须在性能和一致性之间做出权衡
如果真的有必要的话， redis集群可能会在将来提供同步地执行写命令的方法

redis集群另外一种可能会丢失命令的情况是， 集群出现网络分裂， 并且一个客户端与至少包括一个主节点在内的少数实例被孤立
举个例子， 假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点， 其中 A 、B 、C 为主节点， 而 A1 、B1 、C1 分别为三个主节点的从节点， 另外还有一个客户端 Z1 
假设集群中发生网络分裂， 那么集群可能会分裂为两方， 大多数的一方包含节点 A 、C 、A1 、B1 和 C1 ， 而少数的一方则包含节点 B 和客户端 Z1 
在网络分裂期间， 主节点 B 仍然会接受 Z1 发送的写命令：
如果网络分裂出现的时间很短， 那么集群会继续正常运行
但是， 如果网络分裂出现的时间足够长， 使得大多数一方将从节点 B1 设置为新的主节点， 并使用 B1 来代替原来的主节点 B ， 那么 Z1 发送给主节点 B 的写命令将丢失
注意， 在网络分裂出现期间， 客户端 Z1 可以向主节点 B 发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间， 是redis集群的一个重要的配置选项
对于大多数一方来说， 如果一个主节点未能在节点超时时间所设定的时限内重新联系上集群， 那么集群会将这个主节点视为下线， 并使用从节点来代替这个主节点继续工作
对于少数一方， 如果一个主节点未能在节点超时时间所设定的时限内重新联系上集群， 那么它将停止处理写命令， 并向客户端报告错误

创建并使用redis集群
redis集群由多个运行在集群模式下的redis实例组成， 实例的集群模式需要通过配置来开启， 开启集群模式的实例将可以使用集群特有的功能和命令
以下是一个包含了最少选项的集群配置文件示例：
port 7000
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
appendonly yes
文件中的 cluster-enabled 选项用于开实例的集群模式， 而 cluster-conf-file 选项则设定了保存节点配置文件的路径， 默认值为 nodes.conf

节点配置文件无须人为修改， 它由redis集群在启动时创建， 并在有需要时自动进行更新
要让集群正常运作至少需要三个主节点， 不过在刚开始试用集群功能时， 强烈建议使用六个节点： 其中三个为主节点， 而其余三个则是各个主节点的从节点
首先， 让我们进入一个新目录， 并创建六个以端口号为名字的子目录， 稍后我们在将每个目录中运行一个redis实例：
mkdir cluster-test
cd cluster-test
mkdir 7000 7001 7002 7003 7004 7005
在文件夹 7000 至 7005 中， 各创建一个 redis.conf 文件， 文件的内容可以使用上面的示例配置文件， 但记得将配置中的端口号从 7000 改为与文件夹名字相同的号码。

使用类似以下命令， 在每个标签页中打开一个实例：
cd 7000
../redis-server ./redis.conf
实例打印的日志显示， 因为 nodes.conf 文件不存在， 所以每个节点都为它自身指定了一个新的 ID
[82462] 26 Nov 11:56:55.329 * No cluster configuration found, I'm 97a3a64667477371c4479320d683e4c8db5858b1
实例会一直使用同一个 ID ， 从而在集群中保持一个唯一的名字
每个节点都使用 ID 而不是 IP 或者端口号来记录其他节点， 因为 IP 地址和端口号都可能会改变， 而这个唯一的标识符则会在节点的整个生命周期中一直保持不变，我们将这个标识符称为节点 ID

创建集群
现在我们已经有了六个正在运行中的redis实例， 接下来我们需要使用这些实例来创建集群， 并为每个节点编写配置文件
通过使用 redis 集群命令行工具 redis-trib ， 编写节点配置文件的工作可以非常容易地完成： redis-trib 位于 redis 源码的 src 文件夹中， 它是一个 Ruby 程序， 这个程序通过向实例发送特殊命令来完成创建新集群， 检查集群， 或者对集群进行重新分片等工作
我们需要执行以下命令来创建集群：
./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005

命令的意义如下：
给定 redis-trib.rb 程序的命令是 create ， 这表示我们希望创建一个新的集群
选项 --replicas 1 表示我们希望为集群中的每个主节点创建一个从节点
之后跟着的其他参数则是实例的地址列表， 我们希望程序使用这些地址所指示的实例来创建新集群
简单来说， 以上命令的意思就是让 redis-trib 程序创建一个包含三个主节点和三个从节点的集群

接着， redis-trib 会打印出一份预想中的配置，如果没问题的， 可以输入 yes ， redis-trib 就会将这份配置应用到集群当中：
>>> Creating cluster
Connecting to node 127.0.0.1:7000: OK
Connecting to node 127.0.0.1:7001: OK
Connecting to node 127.0.0.1:7002: OK
Connecting to node 127.0.0.1:7003: OK
Connecting to node 127.0.0.1:7004: OK
Connecting to node 127.0.0.1:7005: OK
>>> Performing hash slots allocation on 6 nodes...
Using 3 masters:
127.0.0.1:7000
127.0.0.1:7001
127.0.0.1:7002
127.0.0.1:7000 replica #1 is 127.0.0.1:7003
127.0.0.1:7001 replica #1 is 127.0.0.1:7004
127.0.0.1:7002 replica #1 is 127.0.0.1:7005
M: 9991306f0e50640a5684f1958fd754b38fa034c9 127.0.0.1:7000
slots:0-5460 (5461 slots) master
M: e68e52cee0550f558b03b342f2f0354d2b8a083b 127.0.0.1:7001
slots:5461-10921 (5461 slots) master
M: 393c6df5eb4b4cec323f0e4ca961c8b256e3460a 127.0.0.1:7002
slots:10922-16383 (5462 slots) master
S: 48b728dbcedff6bf056231eb44990b7d1c35c3e0 127.0.0.1:7003
S: 345ede084ac784a5c030a0387f8aaa9edfc59af3 127.0.0.1:7004
S: 3375be2ccc321932e8853234ffa87ee9fde973ff 127.0.0.1:7005
Can I set the above configuration? (type 'yes' to accept): yes
输入 yes 并按下回车确认之后， 集群就会将配置应用到各个节点， 并连接起各个节点：

>>> Nodes configuration updated
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join...
>>> Performing Cluster Check (using node 127.0.0.1:7000)
M: 9991306f0e50640a5684f1958fd754b38fa034c9 127.0.0.1:7000
slots:0-5460 (5461 slots) master
M: e68e52cee0550f558b03b342f2f0354d2b8a083b 127.0.0.1:7001
slots:5461-10921 (5461 slots) master
M: 393c6df5eb4b4cec323f0e4ca961c8b256e3460a 127.0.0.1:7002
slots:10922-16383 (5462 slots) master
M: 48b728dbcedff6bf056231eb44990b7d1c35c3e0 127.0.0.1:7003
slots: (0 slots) master
M: 345ede084ac784a5c030a0387f8aaa9edfc59af3 127.0.0.1:7004
slots: (0 slots) master
M: 3375be2ccc321932e8853234ffa87ee9fde973ff 127.0.0.1:7005
slots: (0 slots) master
[OK] All nodes agree about slots configuration.
如果一切正常的话， redis-trib 将输出以下信息：

>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
这表示集群中的 16384 个槽都有至少一个主节点在处理， 集群运作正常

redis集群现阶段的一个问题是客户端实现很少。 以下是一些：

redis-rb-cluster 是 Ruby 的实现， 用于作为其他实现的参考。 该实现是对 redis-rb 的一个简单包装， 高效地实现了与集群进行通讯所需的最少语义
redis-py-cluster 看上去是 redis-rb-cluster 的一个 Python 版本， 这个项目有一段时间没有更新了（最后一次提交是在六个月之前）， 不过可以将这个项目用作学习集群的起点
流行的 Predis 曾经对早期的redis集群有过一定的支持， 但我不确定它对集群的支持是否完整， 也不清楚它是否和最新版本的redis集群兼容 （因为新版的 Redis 集群将槽的数量从 4k 改为 16k 了）。
redis unstable 分支中的 redis-cli 程序实现了非常基本的集群支持， 可以使用命令 redis-cli -c 来启动
测试redis集群比较简单的办法就是使用 redis-rb-cluster 或者 redis-cli ， 接下来我们将使用 redis-cli 为例来进行演示：
$ redis-cli -c -p 7000
redis 127.0.0.1:7000> set foo bar
-> Redirected to slot [12182] located at 127.0.0.1:7002
OK
redis 127.0.0.1:7002> set hello world
-> Redirected to slot [866] located at 127.0.0.1:7000
OK
redis 127.0.0.1:7000> get foo
-> Redirected to slot [12182] located at 127.0.0.1:7002
"bar"
redis 127.0.0.1:7000> get hello
-> Redirected to slot [866] located at 127.0.0.1:7000
"world"

redis-cli 对集群的支持是非常基本的， 所以它总是依靠redis集群节点来将它转向至正确的节点
一个真正的集群客户端应该做得比这更好： 它应该用缓存记录哈希槽与节点地址之间的映射， 从而直接将命令发送到正确的节点上
这种映射只会在集群的配置出现某些修改时变化， 比如说在一次故障转移后， 或者系统管理员通过添加节点或移除节点来修改了集群的布局后， 诸如此类
